Source codes of the our paper titled "Target-oriented Cross Modal Transformer for Multimodal Aspect-based Sentiment Analysis"

For visual objects in dataset, we perform YOLOv5x6 to detect objects, https://github.com/ultralytics/yolov5
Applying the ViT-GPT2 to generate image captions, https://huggingface.co/nlpconnect/vit-gpt2-image-captioning
The face descriptions from the FITE Model, https://github.com/yhit98/FITE
The OCR text of images extracted from Google's Tesseract OCR engine, https://github.com/madmaze/pytesseract
Obtained ANPs of each image following the image preprocessing procedure of CMMT model, https://github.com/yangli-hub/CMMT-Code
Dataset you can get at: https://drive.google.com/drive/folders/1rm0FtHOTMUfZfRjWIE9Ukn_1D5MDXQy3

