Source codes of the our paper titled "TCMT: Target-oriented Cross Modal Transformer for Multimodal Aspect-Based Sentiment Analysis", which has been accepted by the journal Expert Systems with Applications (2024).  url: https://www.sciencedirect.com/science/article/abs/pii/S095741742402685X

<img src="https://github.com/ZouWang-spider/TCMT/blob/main/TCMT/DataProcess/TCMT.png" alt="TCMT Model" width="500"/>

# AESC

For visual objects in dataset, we perform YOLOv5 to detect objects, https://github.com/ultralytics/yolov5

Applying the ViT-GPT2 to generate image captions, https://huggingface.co/nlpconnect/vit-gpt2-image-captioning

The face descriptions from the FITE Model, https://github.com/yhit98/FITE , need tool at :https://huggingface.co/openai/clip-vit-base-patch16

The OCR text of images extracted from Google's Tesseract OCR engine, https://github.com/madmaze/pytesseract

Obtained ANPs of each image following the image preprocessing procedure of CMMT model, https://github.com/yangli-hub/CMMT-Code

Dataset you can get at: https://drive.google.com/drive/folders/1rm0FtHOTMUfZfRjWIE9Ukn_1D5MDXQy3


